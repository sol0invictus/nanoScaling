# -----------------------------------------------------------------------------
# Structured Weight Decay Experiment Configuration
# -----------------------------------------------------------------------------

# Experiment-Specific
group_mode: "row" # 'row' for neuron pruning, 'col' for feature pruning
epsilon_decay: 1e-5

# I/O
out_dir: "out/structured_decay_demo"
eval_interval: 100
log_interval: 10
eval_iters: 20
eval_only: false
always_save_checkpoint: false
init_from: "scratch"

# Logging
tensorboard_log: true
tensorboard_run_name: "struct_decay_row_demo"

# Data
dataset: "shakespeare" # Use smaller dataset for testing
gradient_accumulation_steps: 1
batch_size: 16
block_size: 256

# Model Architecture (Small for testing)
n_layer: 4
n_head: 4
n_embd: 128
dropout: 0.0
bias: false

# Architecture Toggles
use_rmsnorm: true
use_rope: true
use_swiglu: true
multiple_of: 32

# Optimizer
learning_rate: 0.001
max_iters: 500
weight_decay: 0.1
beta1: 0.9
beta2: 0.99
grad_clip: 1.0

# LR Scheduler
decay_lr: true
warmup_iters: 50
lr_decay_iters: 500
min_lr: 0.0001
# System
device: "cuda"
dtype: "bfloat16"
compile: false # compile often slows down short debug runs
backend: "nccl"
